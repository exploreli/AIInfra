{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628cb90d",
   "metadata": {},
   "source": [
    "<!--Copyright © ZOMI 适用于[License](https://github.com/Infrasys-AI/AIInfra)版权许可-->\n",
    "\n",
    "# CODE 01: Qwen3-4B 模型微调\n",
    "\n",
    "LLM 的微调技术是将预训练模型适配到特定任务的关键环节。面对不同的数据特性和资源约束，选择合适的微调方法至关重要。\n",
    "\n",
    "本文将使用**Qwen3-4B**模型作为基础模型，对比全参数微调、LoRA（Low-Rank Adaptation）、Prompt Tuning 和指令微调四种主流技术，分析它们在**效果、效率和数据需求**方面的差异，并探索**数据集类型**（通用/领域/小样本）与微调技术的适配关系。\n",
    "\n",
    "## 2. 实验设置\n",
    "\n",
    "首先安装必要的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装所需库\n",
    "!pip install transformers peft datasets torch accelerate unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, PromptTuningConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 加载 Qwen3-4B 模型和 tokenizer\n",
    "model_name = \"Qwen/Qwen3-4B-Instruct\"  # 使用 Qwen3-4B 指令微调版本\n",
    "max_seq_length = 2048  # 最大序列长度\n",
    "load_in_4bit = True    # 使用 4bit 量化减少显存占用\n",
    "\n",
    "# 使用 Unsloth 优化加载模型\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    trust_remote_code=True  # Qwen 模型需要此参数\n",
    ")\n",
    "\n",
    "# 添加 pad_token 以便于批处理\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"模型和分词器加载完成\")\n",
    "print(f\"模型参数量: {model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681fdc88",
   "metadata": {},
   "source": [
    "## 3. 数据集构建\n",
    "\n",
    "不同微调技术对数据集格式有不同要求。以下是**指令微调**所需的数据集格式示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7627a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指令微调数据集格式示例\n",
    "instruction_dataset = [\n",
    "    {\n",
    "        \"instruction\": \"判断情感倾向\",\n",
    "        \"input\": \"这部电影的视觉效果很棒，但剧情有些乏味\",\n",
    "        \"output\": \"混合情感：正面评价视觉效果，负面评价剧情\",\n",
    "        \"system\": \"你是一个专业的情感分析助手\",\n",
    "        \"history\": []\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"生成产品描述\",\n",
    "        \"input\": \"智能手机，品牌：Apple，型号：iPhone 15，特点：A17 芯片、4800 万像素相机\",\n",
    "        \"output\": \"Apple iPhone 15 搭载强大的 A17 芯片和 4800 万像素高清相机，提供卓越性能和拍摄体验。\",\n",
    "        \"system\": \"你是一个产品描述生成器\",\n",
    "        \"history\": []\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"翻译成英文\",\n",
    "        \"input\": \"今天天气很好，我们一起去公园吧\",\n",
    "        \"output\": \"The weather is nice today, let's go to the park together.\",\n",
    "        \"system\": \"你是一个翻译助手\",\n",
    "        \"history\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "# 将示例数据集保存为 JSON 文件\n",
    "import json\n",
    "with open(\"instruction_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(instruction_dataset, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"指令微调数据集示例已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5cf94a",
   "metadata": {},
   "source": [
    "对于**通用文本生成**任务，数据集格式可以更简单："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7aa2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通用文本数据集格式示例\n",
    "general_dataset = [\n",
    "    {\n",
    "        \"text\": \"LLM 是人工智能领域的重要突破，它们通过在大量文本数据上进行预训练，学习语言的统计规律和语义表示。\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"迁移学习使模型能够将在一个任务上学到的知识应用到其他相关任务上，大大减少了数据需求和训练时间。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "with open(\"general_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(general_dataset, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"通用文本数据集示例已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aca0c5",
   "metadata": {},
   "source": [
    "## 4. 数据预处理\n",
    "\n",
    "我们需要根据不同的微调方法对数据进行相应处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_instruction_data(examples):\n",
    "    \"\"\"处理指令微调数据\"\"\"\n",
    "    instructions = []\n",
    "    \n",
    "    for i in range(len(examples[\"instruction\"])):\n",
    "        instruction = str(examples[\"instruction\"][i])\n",
    "        input_text = str(examples[\"input\"][i]) if \"input\" in examples and examples[\"input\"][i] else \"\"\n",
    "        output_text = str(examples[\"output\"][i])\n",
    "        system_text = str(examples[\"system\"][i]) if \"system\" in examples and examples[\"system\"][i] else \"\"\n",
    "        \n",
    "        # 构建符合 Qwen3 格式的输入\n",
    "        if system_text:\n",
    "            text = f\"<|im_start|>system\\n{system_text}<|im_end|>\\n\"\n",
    "        else:\n",
    "            text = \"\"\n",
    "            \n",
    "        if input_text:\n",
    "            user_content = f\"{instruction}\\n{input_text}\"\n",
    "        else:\n",
    "            user_content = instruction\n",
    "            \n",
    "        text += f\"<|im_start|>user\\n{user_content}<|im_end|>\\n\"\n",
    "        text += f\"<|im_start|>assistant\\n{output_text}<|im_end|>\"\n",
    "        \n",
    "        instructions.append(text)\n",
    "    \n",
    "    return tokenizer(\n",
    "        instructions,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_seq_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "def preprocess_general_data(examples):\n",
    "    \"\"\"处理通用文本数据\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_seq_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# 加载示例数据集（实际应用中替换为真实数据）\n",
    "dataset = load_dataset(\"json\", data_files=\"instruction_dataset.json\", split=\"train\")\n",
    "\n",
    "# 应用预处理\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_instruction_data,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names\n",
    ")\n",
    "\n",
    "# 分割训练集和验证集\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f 验证集大小: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b160dcf",
   "metadata": {},
   "source": [
    "## 3. 全参数微调\n",
    "\n",
    "全参数微调通过**反向传播算法更新模型的所有可训练参数**。其数学本质可以表示为：\n",
    "\n",
    "θ_min = argmin_θ (1/N) * Σ_{i=1}^N L(f_θ(x_i), y_i)\n",
    "\n",
    "其中 f_θ表示参数化模型，L 为损失函数，N 为样本数量。\n",
    "\n",
    "这种方法的主要优势是能够充分利用所有模型参数进行任务适配，但缺点是**计算成本高**，对于大模型来说需要大量的显存和计算资源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./full_finetune_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,  # 较小的批大小以适应显存\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-6,  # 全参数微调使用较小的学习率\n",
    "    weight_decay=0.01,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,  # 使用混合精度训练节省显存\n",
    ")\n",
    "\n",
    "# 创建 Trainer 实例\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 开始训练（注释掉实际训练代码以便演示）\n",
    "# trainer.train()\n",
    "\n",
    "print(\"全参数微调完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893bd97",
   "metadata": {},
   "source": [
    "全参数微调的主要优点是能够**充分利用模型的全部能力**，通常在数据充足的情况下能达到最佳性能。然而，它的计算成本非常高——对于 Qwen3-4B 这样的模型，需要大量的 GPU 显存和计算时间。\n",
    "\n",
    "此外，全参数微调还容易导致**灾难性遗忘**，即模型在适应新任务时丢失了预训练中获得的一般知识。\n",
    "\n",
    "## 4. LoRA 微调\n",
    "\n",
    "LoRA 是一种**参数高效微调**（PEFT）技术，其核心思想是通过**低秩分解**来限制可训练参数的数量。具体而言，LoRA 将权重更新矩阵ΔW 分解为两个低秩矩阵的乘积：\n",
    "\n",
    "W + ΔW = W + BA\n",
    "\n",
    "其中 W 是预训练权重矩阵，A ∈ R^{r×d}和 B ∈ R^{d×r}是低秩矩阵，r 是秩（r << d）。\n",
    "\n",
    "这种分解的数学基础是**奇异值分解**（SVD）定理，该定理表明任何矩阵都可以被分解为奇异值和奇异向量的乘积，而低秩近似则保留了矩阵中最重要的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2127e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LoRA 配置\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # 秩\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# 创建 LoRA 模型\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,  # LoRA 可以使用更大的批大小\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,  # LoRA 可以使用更大的学习率\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# 创建 Trainer\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 开始训练（注释掉实际训练代码以便演示）\n",
    "# lora_trainer.train()\n",
    "\n",
    "print(\"LoRA 微调完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa1649",
   "metadata": {},
   "source": [
    "LoRA 的主要优势在于：\n",
    "1.  **参数效率**：只需要训练极少量参数（通常小于原模型参数的 1%）\n",
    "2.  **内存友好**：大幅降低显存需求，使得在消费级 GPU 上微调大模型成为可能\n",
    "3.  **模块化**：可以为不同任务训练多个适配器，然后灵活切换\n",
    "\n",
    "实验表明，LoRA 能够保持原始模型大部分性能，同时显著减少训练时间和计算资源需求。\n",
    "\n",
    "## 5. Prompt 微调\n",
    "\n",
    "Prompt Tuning 是一种**轻量级微调方法**，它在输入层插入**可训练的虚拟令牌**（virtual tokens），而保持预训练模型的参数不变。这些虚拟令牌作为连续提示，引导模型更好地执行特定任务。\n",
    "\n",
    "形式上，Prompt Tuning 将原始输入 x 转换为模板化提示 x'，通过构造映射函数 P: X → X'来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 Prompt Tuning 配置\n",
    "prompt_config = PromptTuningConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    num_virtual_tokens=20,  # 虚拟令牌数量\n",
    "    tokenizer_name=model_name\n",
    ")\n",
    "\n",
    "# 创建 Prompt Tuning 模型\n",
    "prompt_model = get_peft_model(model, prompt_config)\n",
    "prompt_model.print_trainable_parameters()\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./prompt_tuning_results\",\n",
    "    num_train_epochs=5,  # Prompt Tuning 通常需要更多训练轮次\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-3,  # Prompt Tuning 通常需要更高学习率\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# 创建 Trainer\n",
    "prompt_trainer = Trainer(\n",
    "    model=prompt_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 开始训练（注释掉实际训练代码以便演示）\n",
    "# prompt_trainer.train()\n",
    "\n",
    "print(\"Prompt Tuning 完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d140f2",
   "metadata": {},
   "source": [
    "Prompt Tuning 的优势在于：\n",
    "1.  **极高的参数效率**：只需要训练极少量的参数（仅虚拟令牌对应的参数）\n",
    "2.  **避免灾难性遗忘**：由于原始模型参数被冻结，预训练知识得到保留\n",
    "3.  **多任务学习**：可以为不同任务学习不同的提示，然后共享同一基础模型\n",
    "\n",
    "Prompt Tuning 特别适合**少样本学习**场景，但在复杂任务上可能性能不如其他方法。\n",
    "\n",
    "## 6. 指令微调\n",
    "\n",
    "指令微调是**监督微调**（SFT）的一种形式，它使用**标注的输入-输出对**进行有监督训练，损失函数通常采用交叉熵（语言建模目标）。与全参数微调不同，指令微调通常专注于使模型遵循指令和完成特定任务格式。\n",
    "\n",
    "指令微调的核心思想是通过高质量的指令-回答对来训练模型，使其能够更好地理解和遵循人类指令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指令微调需要特定的数据格式\n",
    "# 这里我们使用前面创建的指令数据集\n",
    "\n",
    "# 使用 LoRA 进行指令微调（指令微调通常与参数高效方法结合）\n",
    "instruct_lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "instruct_model = get_peft_model(model, instruct_lora_config)\n",
    "instruct_model.print_trainable_parameters()\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./instruction_tuning_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# 创建 Trainer\n",
    "instruct_trainer = Trainer(\n",
    "    model=instruct_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 开始训练（注释掉实际训练代码以便演示）\n",
    "# instruct_trainer.train()\n",
    "\n",
    "print(\"指令微调完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff0147",
   "metadata": {},
   "source": [
    "指令微调的优势包括：\n",
    "\n",
    "1.  **任务特异性**：能够使模型更好地适应特定任务格式和指令\n",
    "2.  **数据效率**：通常比全参数微调需要更少的数据\n",
    "3.  **可组合性**：可以与 LoRA 等参数高效方法结合使用\n",
    "\n",
    "然而，指令微调**依赖高质量标注数据**，如果指令-回答对质量不高，可能会限制模型性能。\n",
    "\n",
    "## 7. 实验结果与分析\n",
    "\n",
    "为了评估不同微调方法的性能，我们需要在测试集上计算模型的困惑度（perplexity）或任务特定指标："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47602643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainer, dataset):\n",
    "    # 评估模型性能\n",
    "    eval_results = trainer.evaluate(eval_dataset=dataset)\n",
    "    perplexity = torch.exp(torch.tensor(eval_results[\"eval_loss\"]))\n",
    "    return {\n",
    "        \"eval_loss\": eval_results[\"eval_loss\"],\n",
    "        \"perplexity\": perplexity.item()\n",
    "    }\n",
    "\n",
    "# 假设我们已经训练了所有模型\n",
    "# full_finetune_results = evaluate_model(trainer, eval_dataset)\n",
    "# lora_results = evaluate_model(lora_trainer, eval_dataset)\n",
    "# prompt_tuning_results = evaluate_model(prompt_trainer, eval_dataset)\n",
    "# instruction_tuning_results = evaluate_model(instruct_trainer, eval_dataset)\n",
    "\n",
    "print(\"性能评估完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb334cd",
   "metadata": {},
   "source": [
    "除了性能外，训练效率和资源消耗也是选择微调方法的重要考量因素："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43053773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "\n",
    "def measure_training_efficiency(trainer, model_name):\n",
    "    # 测量训练时间和内存使用\n",
    "    start_time = time.time()\n",
    "    start_memory = psutil.virtual_memory().used\n",
    "    \n",
    "    # 实际训练代码会在这里执行\n",
    "    # trainer.train()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_memory = psutil.virtual_memory().used\n",
    "    \n",
    "    return {\n",
    "        \"training_time\": end_time - start_time,\n",
    "        \"memory_used\": end_memory - start_memory,\n",
    "        \"trainable_params\": sum(p.numel() for p in trainer.model.parameters() if p.requires_grad),\n",
    "        \"total_params\": sum(p.numel() for p in trainer.model.parameters())\n",
    "    }\n",
    "\n",
    "# 测量各方法的效率\n",
    "# full_finetune_efficiency = measure_training_efficiency(trainer, \"Full Finetune\")\n",
    "# lora_efficiency = measure_training_efficiency(lora_trainer, \"LoRA\")\n",
    "# prompt_tuning_efficiency = measure_training_efficiency(prompt_trainer, \"Prompt Tuning\")\n",
    "# instruction_tuning_efficiency = measure_training_efficiency(instruct_trainer, \"Instruction Tuning\")\n",
    "\n",
    "print(\"效率评估完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5aecb",
   "metadata": {},
   "source": [
    "根据理论分析和实验经验，我们可以总结出数据集特性与微调技术的适配关系：\n",
    "\n",
    "| **微调方法** | **数据需求** | **计算效率** | **适合场景** | **实现难度** |\n",
    "|------------|------------|------------|------------|------------|\n",
    "| **全参数微调** | 大量高质量数据 | 低 | 数据充足且与预训练数据相似度高 | 中等 |\n",
    "| **LoRA** | 中等规模数据 | 高 | 计算资源有限，需要快速适配 | 低 |\n",
    "| **Prompt Tuning** | 少样本学习 | 极高 | 数据稀缺，需要快速部署 | 低 |\n",
    "| **指令微调** | 高质量指令-回答对 | 中等 | 任务特定格式和指令遵循 | 中等 |\n",
    "\n",
    "具体来说：\n",
    "\n",
    "1.  **数据量少，数据相似度高**：适合 Prompt Tuning 或 LoRA，只需要修改最后几层或添加少量参数。\n",
    "\n",
    "2.  **数据量少，数据相似度低**：适合 LoRA 或 Adapter 方法，可以冻结预训练模型的初始层，只训练较高层。\n",
    "\n",
    "3.  **数据量大，数据相似度低**：考虑全参数微调或领域自适应预训练（DAPT），但由于数据差异大，可能需要更多训练时间。\n",
    "\n",
    "4.  **数据量大，数据相似度高**：全参数微调通常能获得最佳性能，这是最理想的情况。\n",
    "\n",
    "## 8. 总结与思考\n",
    "\n",
    "在实际应用中，选择微调技术时需要综合考虑数据特性（数量、质量、与预训练数据的相似度）、计算资源约束、任务要求和部署环境等因素。对于大多数实际应用场景，**LoRA**提供了最佳的权衡，而**Prompt Tuning**则在极端资源约束或数据稀缺环境下更具优势。\n",
    "\n",
    "未来的研究方向可能包括这些技术的组合使用（如 LoRA+Prompt Tuning）、自适应微调策略（根据数据特性动态选择微调方法）以及更高效的参数高效微调技术。\n",
    "\n",
    "## 参考文献\n",
    "\n",
    "1. Hu, E. J., et al. (2021). LoRA: Low-Rank Adaptation of Large Language Models. arXiv:2106.09685.\n",
    "2. Liu, X., et al. (2019). Multi-Task Deep Neural Networks for Natural Language Understanding. arXiv:1901.11504.\n",
    "3. Shin, T., et al. (2020). AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. arXiv:2010.15980."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
